{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QXUJN9MoKWQ",
        "outputId": "18612218-e61f-46f9-ea7f-bd520c6842f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.7.22)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.3.5 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "pip install keras-tuner\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_3y_cxvgn3If",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1bc04ad-079a-4b55-f638-ed89e564d502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-1e3fc80dd604>:7: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner.tuners import RandomSearch\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner import HyperModel\n",
        "from kerastuner import Objective\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC_XNULXEzJA",
        "outputId": "fda2d2e1-05d1-456e-f44d-1a661df96120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 06m 15s]\n",
            "val_loss: 0.09864064306020737\n",
            "\n",
            "Best val_loss So Far: 0.09813291827837627\n",
            "Total elapsed time: 00h 27m 48s\n"
          ]
        }
      ],
      "source": [
        "# Load necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner import HyperModel\n",
        "from kerastuner import Objective\n",
        "\n",
        "\n",
        "\n",
        "# Split data into train and test sets\n",
        "#np.random.seed(123)  # For reproducibility\n",
        "#train_data, test_data = train_test_split(filtered_data_NN, test_size=0.3)\n",
        "\n",
        "subset_train = pd.read_csv(\"/content/subset_train.csv\")\n",
        "subset_test = pd.read_csv(\"/content/subset_test.csv\")\n",
        "\n",
        "# Predictor variables\n",
        "X_train = subset_train[[\"VehPower\", \"VehAge\", \"DrivAge\", \"BonusMalus\",\n",
        "                      \"VehBrand_encoded\", \"VehGas_encoded\",\n",
        "                      \"Region_encoded\", \"Area_encoded\", \"Density\"]]\n",
        "\n",
        "X_test = subset_test[[\"VehPower\", \"VehAge\", \"DrivAge\", \"BonusMalus\",\n",
        "                      \"VehBrand_encoded\", \"VehGas_encoded\",\n",
        "                      \"Region_encoded\", \"Area_encoded\", \"Density\"]]\n",
        "\n",
        "# Target variables\n",
        "y_train = subset_train[\"ClaimNb\"]\n",
        "y_test = subset_test[\"ClaimNb\"]\n",
        "\n",
        "y_train_sev = subset_train[\"ClaimAmount\"]\n",
        "y_test_sev = subset_test[\"ClaimAmount\"]\n",
        "\n",
        "# Define the model-building function\n",
        "class MyHyperModel(HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = keras.Sequential()\n",
        "        model.add(layers.Dense(units=hp.Int('units1', min_value=32, max_value=512, step=32),\n",
        "                               input_shape=(9,),\n",
        "                               activation=hp.Choice('activation1', values=['relu', 'tanh', 'sigmoid'])))  # Activation for first layer\n",
        "        model.add(layers.Dense(units=hp.Int('units2', min_value=16, max_value=256, step=16),\n",
        "                               activation=hp.Choice('activation2', values=['relu', 'tanh', 'sigmoid'])))\n",
        "        model.add(layers.Dense(units=hp.Int('units3', min_value=8, max_value=256, step=16),\n",
        "                               activation=hp.Choice('activation3', values=['relu', 'tanh', 'sigmoid'])))\n",
        "        model.add(layers.Dense(units=1, activation='linear'))\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "            loss='mean_squared_error'\n",
        "        )\n",
        "        return model\n",
        "\n",
        "# Initialize the tuner\n",
        "tuner1 = RandomSearch(\n",
        "    MyHyperModel(),\n",
        "    objective=Objective('val_loss', direction='min'),  # Use 'val_loss' since you're using mean squared error as loss\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='my_dir1',\n",
        "    project_name='helloworld'\n",
        ")\n",
        "\n",
        "\n",
        "# Fit the tuner with batch size and epochs\n",
        "tuner1.search(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0rSvdt-yFEx",
        "outputId": "7ef6a29b-15c0-4795-f06a-3191245fe6d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in my_dir1/helloworld\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_loss\", direction=\"min\")\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "units1: 64\n",
            "activation1: tanh\n",
            "units2: 80\n",
            "activation2: sigmoid\n",
            "units3: 88\n",
            "activation3: relu\n",
            "learning_rate: 0.01\n",
            "Score: 0.09813291827837627\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "units1: 192\n",
            "activation1: relu\n",
            "units2: 224\n",
            "activation2: relu\n",
            "units3: 184\n",
            "activation3: sigmoid\n",
            "learning_rate: 0.01\n",
            "Score: 0.09828082472085953\n",
            "\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "units1: 512\n",
            "activation1: tanh\n",
            "units2: 256\n",
            "activation2: tanh\n",
            "units3: 136\n",
            "activation3: sigmoid\n",
            "learning_rate: 0.001\n",
            "Score: 0.09837942322095235\n",
            "\n",
            "Trial 3 summary\n",
            "Hyperparameters:\n",
            "units1: 192\n",
            "activation1: relu\n",
            "units2: 160\n",
            "activation2: tanh\n",
            "units3: 56\n",
            "activation3: sigmoid\n",
            "learning_rate: 0.001\n",
            "Score: 0.09854529798030853\n",
            "\n",
            "Trial 4 summary\n",
            "Hyperparameters:\n",
            "units1: 352\n",
            "activation1: relu\n",
            "units2: 192\n",
            "activation2: sigmoid\n",
            "units3: 168\n",
            "activation3: sigmoid\n",
            "learning_rate: 0.01\n",
            "Score: 0.09864064306020737\n"
          ]
        }
      ],
      "source": [
        "#gives optimal parameters for Frequency model\n",
        "tuner1.results_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0zbOz2qqg2wC"
      },
      "outputs": [],
      "source": [
        "# Load necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner import HyperModel\n",
        "from kerastuner import Objective\n",
        "\n",
        "\n",
        "# Define the model-building function\n",
        "class MyHyperModel(HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = keras.Sequential()\n",
        "        model.add(layers.Dense(units=hp.Int('units1', min_value=32, max_value=512, step=32),\n",
        "                               input_shape=(9,),\n",
        "                               activation=hp.Choice('activation1', values=['relu', 'tanh', 'sigmoid'])))  # Activation for first layer\n",
        "        model.add(layers.Dense(units=hp.Int('units2', min_value=16, max_value=256, step=16),\n",
        "                               activation=hp.Choice('activation2', values=['relu', 'tanh', 'sigmoid'])))\n",
        "        model.add(layers.Dense(units=hp.Int('units3', min_value=8, max_value=128, step=16),\n",
        "                               activation=hp.Choice('activation3', values=['relu', 'tanh', 'sigmoid'])))\n",
        "        model.add(layers.Dense(units=hp.Int('units4', min_value=8, max_value=128, step=16),\n",
        "                               activation=hp.Choice('activation4', values=['relu', 'tanh', 'sigmoid'])))\n",
        "        model.add(layers.Dense(units=1, activation='linear'))\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "            loss='mean_absolute_error'\n",
        "        )\n",
        "        return model\n",
        "\n",
        "# Initialize the tuner\n",
        "tuner2 = RandomSearch(\n",
        "    MyHyperModel(),\n",
        "    objective=Objective('val_loss', direction='min'),  # Use 'val_loss' since you're using mean squared error as loss\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='my_dir2',\n",
        "    project_name='helloworld'\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueXMvDtCy9yy",
        "outputId": "ab30b3f3-470f-40cc-e756-9e2ac8612829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 04m 06s]\n",
            "val_loss: 1421.7837320963542\n",
            "\n",
            "Best val_loss So Far: 1421.1111246744792\n",
            "Total elapsed time: 00h 22m 59s\n"
          ]
        }
      ],
      "source": [
        "# Fit the tuner with batch size and epochs\n",
        "tuner2.search(X_train, y_train_sev, epochs=50, validation_data=(X_test, y_test_sev))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gives optimal parameters for Severity model\n",
        "tuner2.results_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbXvHqAZuJeB",
        "outputId": "d5c283cf-93a1-40bb-d60c-50d77cef79dd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in my_dir2/helloworld\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_loss\", direction=\"min\")\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "units1: 256\n",
            "activation1: sigmoid\n",
            "units2: 32\n",
            "activation2: tanh\n",
            "units3: 72\n",
            "activation3: tanh\n",
            "units4: 88\n",
            "activation4: tanh\n",
            "learning_rate: 0.01\n",
            "Score: 1421.1111246744792\n",
            "\n",
            "Trial 3 summary\n",
            "Hyperparameters:\n",
            "units1: 352\n",
            "activation1: sigmoid\n",
            "units2: 192\n",
            "activation2: sigmoid\n",
            "units3: 8\n",
            "activation3: tanh\n",
            "units4: 120\n",
            "activation4: relu\n",
            "learning_rate: 0.001\n",
            "Score: 1421.1116536458333\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "units1: 416\n",
            "activation1: sigmoid\n",
            "units2: 48\n",
            "activation2: sigmoid\n",
            "units3: 8\n",
            "activation3: relu\n",
            "units4: 88\n",
            "activation4: relu\n",
            "learning_rate: 0.001\n",
            "Score: 1421.1159261067708\n",
            "\n",
            "Trial 4 summary\n",
            "Hyperparameters:\n",
            "units1: 32\n",
            "activation1: relu\n",
            "units2: 64\n",
            "activation2: tanh\n",
            "units3: 120\n",
            "activation3: relu\n",
            "units4: 40\n",
            "activation4: tanh\n",
            "learning_rate: 0.01\n",
            "Score: 1421.7837320963542\n",
            "\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "units1: 256\n",
            "activation1: relu\n",
            "units2: 160\n",
            "activation2: tanh\n",
            "units3: 120\n",
            "activation3: sigmoid\n",
            "units4: 8\n",
            "activation4: relu\n",
            "learning_rate: 0.0001\n",
            "Score: 1994.7347005208333\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}